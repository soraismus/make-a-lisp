'use strict'

blank?                = require './isBlank'
{ jsArray? }          = require './js-types'
{ throwCommentError } = require './error-management'

{
  createStream!
  forEach
  prependValueToStream
  streamEnd?
} = require './stream-utilities'

{
  createMalHash
  createMalKeyword
  createMalList
  createMalNumber
  createMalString
  createMalSymbol
  createMalVector
  FALSE
  NIL
  TRUE
} = require './mal-types'

{ DEREF, QUASIQUOTE, QUOTE, SPLICE-UNQUOTE, UNQUOTE } =
  require './meta-symbols'

atomize = \token ->
  switch
    when integerToken? token then createMalNumber (getIntegerValue token)
    when floatToken? token   then createMalNumber (getFloatValue token)
    when stringToken? token  then createMalString (getStringValue token)
    when keywordToken? token then createMalKeyword (getKeywordValue token)
    when nilToken? token     then NIL
    when trueToken? token    then TRUE
    when falseToken? token   then FALSE
    else                          createMalSymbol token

falseToken? = \token ->
  token == 'false'

floatToken? = \token ->
  /^-?[0-9]+.[0-9]+$/.test token

getCorrespondingMetaSymbol = \metaToken ->
  metaSymbols[metaToken]

getFloatValue = \value ->
  parseFloat (value, 10)

getIntegerValue = \token ->
  parseInt (token, 10)

getStringValue = \val ->
  val.slice(1, val.length - 1)
     .replace(/\\"/g, '"')
     .replace(/\\n/g, '\n')

getSeqConstructor = \endToken ->
  seqTypeConstructors[endToken] ??  \value -> throw 'Invalid end token'

increment = (cache, token) ->
  cache[token]++

integerToken? = \token ->
  /^-?[0-9]+$/.test token

getKeywordValue = \val ->
  val[1..]

keywordToken? = \token ->
  colon = ':'
  token[0] == colon

stringToken? = \token ->
  doubleQuote = '"'
  token[0] == doubleQuote

available? = \str ->
  ! blank? str

comment? = \token ->
  token[0] == commentStart

manageEmptyTokens! = \tokens ->
  # If the `tokens` array should only be empty for comments.
  throwCommentError () if tokens.length == 0

meta? = \token ->
  token in metaTokens

metadataMarker? = \token ->
  token == metadataMarker

nilToken? = \token ->
  token == 'nil'

_parse = (token, tokens) ->
  switch
    when start? token then parseSeq token tokens
    when meta? token  then parseMeta (token, tokens)
    else                   atomize token

parse = \tokens ->
  manageEmptyTokens! tokens
  _parse ((shift tokens), tokens)

parseMeta = (metaToken, tokens) ->
  createMalList [
    getCorrespondingMetaSymbol metaToken  
    parse tokens
  ]

parseSeq = \startToken ->
  seqParsers[startToken]

createSeqParser = \endToken \tokens ->
  array = []
  until (token = shift tokens) == endToken
    array.push (_parse (token, tokens))
  getSeqConstructor endToken array

read = \str ->
  parse (tokenize str)

shift = \queue ->
  queue.shift ()

start? = \token ->
  token in startTokens

tokenize = \str ->
  tokenRegex =
    /[\s,]*(~@|[\[\]{}()'`~^@]|"(?:\\.|[^\\"])*"|;.*|[^\s\[\]{}('"`,;)]*)/g
  tokens = []
  while available? (token = tokenRegex.exec(str)[1])
    continue if comment? token
    tokens.push token
  tokens

trueToken? = \token ->
  token == 'true'

listStart      = '('
listEnd        = ')'
vectorStart    = '['
vectorEnd      = ']'
hashmapStart   = '{'
hashmapEnd     = '}'
commentStart   = ';'
deref          = '@'
quote          = '\'' 
quasiquote     = '`'
unquote        = '~'
spliceUnquote  = '~@'
metadataMarker = '^'

startTokens = [listStart, vectorStart, hashmapStart]
metaTokens  = [deref, quote, quasiquote, unquote, spliceUnquote]

metaSymbols =
  '@'  : DEREF
  '`'  : QUASIQUOTE
  '\'' : QUOTE
  '~@' : SPLICE-UNQUOTE
  '~'  : UNQUOTE

seqTypeConstructors =
  ')' : createMalList
  ']' : createMalVector
  '}' : createMalHash

[parseHash, parseList, parseVector] =
  [hashmapEnd, listEnd, vectorEnd].map createSeqParser

seqParsers =
  '(' : parseList
  '[' : parseVector
  '{' : parseHash

module.exports = read
