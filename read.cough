'use strict'

blank?       = require './isBlank'
{ jsArray? } = require './js-types'

{
  createStream!
  forEach
  prependValueToStream
  streamEnd?
} = require './stream-utilities'

{
  createMalHash
  createMalKeyword
  createMalList
  createMalNumber
  createMalString
  createMalSymbol
  createMalVector
  FALSE
  NIL
  TRUE
} = require './mal-types'

{ DEREF, QUASIQUOTE, QUOTE, SPLICE-UNQUOTE, UNQUOTE } =
  require './meta-symbols'

log = console.log

allSeqsAreCompleted? = \cache ->
  ! notAllSeqsAreCompleted? cache

atomize = \token ->
  switch
    when integerToken? token then createMalNumber (getIntegerValue token)
    when floatToken? token   then createMalNumber (getFloatValue token)
    when stringToken? token  then createMalString (getStringValue token)
    when keywordToken? token then createMalKeyword (getKeywordValue token)
    when nilToken? token     then NIL
    when trueToken? token    then TRUE
    when falseToken? token   then FALSE
    else                          createMalSymbol token

falseToken? = \token ->
  token == 'false'

floatToken? = \token ->
  /^-?[0-9]+.[0-9]+$/.test token

getAndValidateNextToken! = \getNextToken ->
  cache =
    '(' : 0
    '[' : 0
    '{' : 0
    ')' : 0
    ']' : 0
    '}' : 0

  stream = ->
    token = getNextToken ()
    increment (cache, token) unless streamEnd? token
    unless startTokensHavePreceded? cache
      throw 'Start tokens must precede end tokens'

    # TODO:
    #if !(start? token && allSeqsAreCompleted? cache)
    #  throw 'Error message TBD'

    if streamEnd? token && notAllSeqsAreCompleted? cache
      throw 'All seqs must be terminated with an appropriate end token'
    token

  (stream[key] = value) for own key, value of getNextToken

  stream

getCorrespondingMetaSymbol = \metaToken ->
  metaSymbols[metaToken]

getFloatValue = \value ->
  parseFloat (value, 10)

getIntegerValue = \token ->
  parseInt (token, 10)

getStringValue = \val ->
  #val.slice(1, val.length - 1)
  #   .replace(/\\"/g, '"')
  #   .replace(/\\n/g, '"')
  val.slice(1, val.length - 1)

getSeqConstructor = \endToken ->
  seqTypeConstructors[endToken] ??  \value -> throw 'Invalid end token'

increment = (cache, token) ->
  cache[token]++

integerToken? = \token ->
  /^-?[0-9]+$/.test token

getKeywordValue = \val ->
  val[1..]

keywordToken? = \token ->
  colon = ':'
  token[0] == colon

stringToken? = \token ->
  doubleQuote = '"'
  token[0] == doubleQuote

available? = \str ->
  ! blank? str

comment? = \token ->
  token[0] == commentStart

end? = \token ->
  token in endTokens

# no-op
ignore! = (stack, token) ->

meta? = \token ->
  token in metaTokens

metadataMarker? = \token ->
  token == metadataMarker

nilToken? = \token ->
  token == 'nil'

notAllSeqsAreCompleted? = \cache ->
  cache[listStart] != cache[listEnd] ||
    cache[vectorStart] != cache[vectorEnd] ||
    cache[hashmapStart] != cache[hashmapEnd]

parseStack = \stack ->
  log 'parseStack'

  metaSymbolInStack? = false
  processingSeq?     = false

  shouldCompleteMetaForm? = ->
    metaSymbolInStack? && !processingSeq?

  completeMetaForm = ->
    log 'completeMetaForm'
    metaSymbolInStack? = false
    array = pop stack
    push (peek stack) (createMalList array)
    log '   stack: '
    log stack

  \token ->
    switch
      when start? token
        log 'start'
        processingSeq? = true
        push stack []
        log '   stack: '
        log stack
      when end? token
        log 'end'
        processingSeq? = false
        array = pop stack
        push (peek stack) (getSeqConstructor token array)
        log '   stack: '
        log stack
        completeMetaForm () if shouldCompleteMetaForm? ()
      when meta? token
        log 'meta'
        metaSymbolInStack? = true
        push stack [getCorrespondingMetaSymbol token]
        log '   stack: '
        log stack
      when shouldCompleteMetaForm? ()
        log 'about to complete metaForm for non-start/end token'
        push (peek stack) (atomize token)
        log '   stack: '
        log stack
        completeMetaForm ()
      else
        log 'default'
        log '   token:'
        log token
        push (peek stack) (atomize token)
        log '   stack: '
        log stack

parseStream = \getNextToken ->
  log 'parseStream'
  token = getNextToken.peek ()
  log ('token: ' + token)
  return (atomize token) unless start? token || meta? token
  stack = []
  parseToken = parseStack stack
  forEach getNextToken parseToken
  pop stack

peek = \stack ->
  stack[stack.length - 1] ?? stack

pop = \stack ->
  stack.pop ()

push = \array \value ->
  array.push value
  array

# TODO: Separate `tokenize` and `parse` into separate files.
read = \str ->
  ; parseStream getAndValidateNextToken! createStream! tokenize ; str

start? = \token ->
  token in startTokens

startTokensHavePreceded? = \cache ->
  cache[listStart] >= cache[listEnd] &&
    cache[vectorStart] >= cache[vectorEnd] &&
    cache[hashmapStart] >= cache[hashmapEnd]

tokenize = \str ->
  tokenRegex =
    /[\s,]*(~@|[\[\]{}()'`~^@]|"(?:\\.|[^\\"])*"|;.*|[^\s\[\]{}('"`,;)]*)/g
  tokens = []
  while available? (token = tokenRegex.exec(str)[1])
    continue if comment? token
    tokens.push token
  tokens

trueToken? = \token ->
  token == 'true'

listStart      = '('
listEnd        = ')'
vectorStart    = '['
vectorEnd      = ']'
hashmapStart   = '{'
hashmapEnd     = '}'
commentStart   = ';'
deref          = '@'
quote          = '\'' 
quasiquote     = '`'
unquote        = '~'
spliceUnquote  = '~@'
metadataMarker = '^'

startTokens = [listStart, vectorStart, hashmapStart]
endTokens   = [listEnd, vectorEnd, hashmapEnd]
metaTokens  = [deref, quote, quasiquote, unquote, spliceUnquote]

metaSymbols =
  '@'  : DEREF
  '`'  : QUASIQUOTE
  '\'' : QUOTE
  '~@' : SPLICE-UNQUOTE
  '~'  : UNQUOTE

seqTypeConstructors =
  ')' : createMalList
  ']' : createMalVector
  '}' : createMalHash

module.exports = read
