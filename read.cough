'use strict'

blank?   = require './isBlank'
jsArray? = require './isJsArray'

{
  createStream!
  forEach
  streamEnd?
} = require './stream-utilities'

{
  createMalHash
  createMalKeyword
  createMalList
  createMalNumber
  createMalString
  createMalSymbol
  createMalVector
  FALSE
  NIL
  TRUE
} = require './types'

{ DEREF, QUASIQUOTE, QUOTE, SPLICE-UNQUOTE, UNQUOTE } =
  require './meta-symbols'

allSeqsAreCompleted? = \cache ->
  ! notAllSeqsAreCompleted? cache

atomize = \token ->
  switch
    when integerToken? token then createMalNumber (getIntegerValue token)
    when floatToken? token   then createMalNumber (getFloatValue token)
    when stringToken? token  then createMalString (getStringValue token)
    when keywordToken? token then createMalKeyword (getKeywordValue token)
    when nilToken? token     then NIL
    when trueToken? token    then TRUE
    when falseToken? token   then FALSE
    else                          createMalSymbol token

falseToken? = \token ->
  token == 'false'

floatToken? = \token ->
  /^-?[0-9]+.[0-9]+$/.test token

getAndValidateNextToken! = \getNextToken ->
  cache =
    '(' : 0
    '[' : 0
    '{' : 0
    ')' : 0
    ']' : 0
    '}' : 0

  ->
    token = getNextToken ()
    increment (cache, token) unless streamEnd? token
    unless startTokensHavePreceded? cache
      throw 'Start tokens must precede end tokens'

    # TODO:
    #if !(start? token && allSeqsAreCompleted? cache)
    #  throw 'Error message TBD'

    if streamEnd? token && notAllSeqsAreCompleted? cache
      throw 'All seqs must be terminated with an appropriate end token'
    token

getFloatValue = \value ->
  parseFloat (value, 10)

getSeqConstructor = \endToken ->
  seqTypeConstructors[endToken] ??  \value -> throw 'Invalid end token'

getIntegerValue = \token ->
  parseInt (token, 10)

increment = (cache, token) ->
  cache[token]++

integerToken? = \token ->
  /^-?[0-9]+$/.test token

getKeywordValue = \val ->
  val[1..]

keywordToken? = \token ->
  colon = ':'
  token[0] == colon

getStringValue = \val ->
  val.slice(1, val.length - 1)
     .replace(/\\"/g, '"')
     .replace(/\\n/g, '"')

stringToken? = \token ->
  doubleQuote = '"'
  token[0] == doubleQuote

available? = \str ->
  ! blank? str

comment? = \token ->
  token[0] == commentStart

end? = \token ->
  token in endTokens

# no-op
ignore! = (stack, token) ->

meta? = \token ->
  token in metaTokens

metadataMarker? = \token ->
  token == metadataMarker

nilToken? = \token ->
  token == 'nil'

notAllSeqsAreCompleted? = \cache ->
  cache[listStart] != cache[listEnd] ||
    cache[vectorStart] != cache[vectorEnd] ||
    cache[hashmapStart] != cache[hashmapEnd]

_parse = \stack \token ->
  switch
    when start? token
      push stack []
    when end? token
      array = pop stack
      push (peek stack) (getSeqConstructor token array)
    else
      push (peek stack) (atomize token)

parse = \getNextToken ->
  token = getNextToken ()
  return token unless start? token
  stack = [[]]
  forEach getNextToken (_parse stack)
  pop stack

peek = \stack ->
  stack[stack.length - 1] ?? stack

pop = \stack ->
  stack.pop ()

push = \array \value ->
  array.push value
  array

read = \str ->
  ; parse getAndValidateNextToken! createStream! tokenize ; str

start? = \token ->
  token in startTokens

startTokensHavePreceded? = \cache ->
  cache[listStart] >= cache[listEnd] &&
    cache[vectorStart] >= cache[vectorEnd] &&
    cache[hashmapStart] >= cache[hashmapEnd]

tokenize = \str ->
  tokenRegex =
    /[\s,]*(~@|[\[\]{}()'`~^@]|"(?:\\.|[^\\"])*"|;.*|[^\s\[\]{}('"`,;)]*)/g
  tokens = []
  while available? (token = tokenRegex.exec(str)[1])
    continue if comment? token
    tokens.push token
  tokens

trueToken? = \token ->
  token == 'true'

listStart      = '('
listEnd        = ')'
vectorStart    = '['
vectorEnd      = ']'
hashmapStart   = '{'
hashmapEnd     = '}'
commentStart   = ';'
deref          = '@'
quote          = '\'' 
quasiquote     = '`'
unquote        = '~'
spliceUnquote  = '~@'
metadataMarker = '^'

startTokens = [listStart, vectorStart, hashmapStart]
endTokens   = [listEnd, vectorEnd, hashmapEnd]
metaTokens  = [deref, quote, quasiquote, unquote, spliceUnquote]

metaSymbols =
  '@'  : DEREF
  '`'  : QUASIQUOTE
  '\'' : QUOTE
  '~@' : SPLICE-UNQUOTE
  '~'  : UNQUOTE

seqTypeConstructors =
  ')' : createMalList
  ']' : createMalVector
  '}' : createMalHash

module.exports = read
